{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a1271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "\n",
    "import os\n",
    "import functools as reduce\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import DataFrame, SQLContext, SparkSession, Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName('MLLib-Machine Learning Model').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf = conf)\n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "473857a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Jai-Ahuja:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MLLib-Machine Learning Model</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1ab83946100>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a33f4b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset and libraries\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "boston = load_boston()\n",
    "\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df['price'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e4f1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+-----+-------+------+-----+-----+\n",
      "|CRIM   |ZN  |INDUS|CHAS|NOX  |RM   |AGE |DIS   |RAD|TAX  |PTRATIO|B     |LSTAT|price|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+-----+-------+------+-----+-----+\n",
      "|0.00632|18.0|2.31 |0.0 |0.538|6.575|65.2|4.09  |1.0|296.0|15.3   |396.9 |4.98 |24.0 |\n",
      "|0.02731|0.0 |7.07 |0.0 |0.469|6.421|78.9|4.9671|2.0|242.0|17.8   |396.9 |9.14 |21.6 |\n",
      "|0.02729|0.0 |7.07 |0.0 |0.469|7.185|61.1|4.9671|2.0|242.0|17.8   |392.83|4.03 |34.7 |\n",
      "|0.03237|0.0 |2.18 |0.0 |0.458|6.998|45.8|6.0622|3.0|222.0|18.7   |394.63|2.94 |33.4 |\n",
      "|0.06905|0.0 |2.18 |0.0 |0.458|7.147|54.2|6.0622|3.0|222.0|18.7   |396.9 |5.33 |36.2 |\n",
      "+-------+----+-----+----+-----+-----+----+------+---+-----+-------+------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.createDataFrame(df)\n",
    "sdf.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2205eb30",
   "metadata": {},
   "source": [
    "### Linear Regression with MLLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f70b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78bff768",
   "metadata": {},
   "source": [
    "# We can't just fit the Linear Regrssion directly over a spark dataframe. We need to create features\n",
    "lr = LinearRegression()\n",
    "lr.fit(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3badf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9428d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[x for x in sdf.columns if x != \"price\"],\n",
    "                           outputCol=\"features\")\n",
    "dataset = assembler.transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce0cf6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+-------+------+-----+-----+--------------------+\n",
      "|   CRIM|  ZN|INDUS|CHAS|  NOX|   RM|  AGE|   DIS|RAD|  TAX|PTRATIO|     B|LSTAT|price|            features|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+-------+------+-----+-----+--------------------+\n",
      "|0.00632|18.0| 2.31| 0.0|0.538|6.575| 65.2|  4.09|1.0|296.0|   15.3| 396.9| 4.98| 24.0|[0.00632,18.0,2.3...|\n",
      "|0.02731| 0.0| 7.07| 0.0|0.469|6.421| 78.9|4.9671|2.0|242.0|   17.8| 396.9| 9.14| 21.6|[0.02731,0.0,7.07...|\n",
      "|0.02729| 0.0| 7.07| 0.0|0.469|7.185| 61.1|4.9671|2.0|242.0|   17.8|392.83| 4.03| 34.7|[0.02729,0.0,7.07...|\n",
      "|0.03237| 0.0| 2.18| 0.0|0.458|6.998| 45.8|6.0622|3.0|222.0|   18.7|394.63| 2.94| 33.4|[0.03237,0.0,2.18...|\n",
      "|0.06905| 0.0| 2.18| 0.0|0.458|7.147| 54.2|6.0622|3.0|222.0|   18.7| 396.9| 5.33| 36.2|[0.06905,0.0,2.18...|\n",
      "|0.02985| 0.0| 2.18| 0.0|0.458| 6.43| 58.7|6.0622|3.0|222.0|   18.7|394.12| 5.21| 28.7|[0.02985,0.0,2.18...|\n",
      "|0.08829|12.5| 7.87| 0.0|0.524|6.012| 66.6|5.5605|5.0|311.0|   15.2| 395.6|12.43| 22.9|[0.08829,12.5,7.8...|\n",
      "|0.14455|12.5| 7.87| 0.0|0.524|6.172| 96.1|5.9505|5.0|311.0|   15.2| 396.9|19.15| 27.1|[0.14455,12.5,7.8...|\n",
      "|0.21124|12.5| 7.87| 0.0|0.524|5.631|100.0|6.0821|5.0|311.0|   15.2|386.63|29.93| 16.5|[0.21124,12.5,7.8...|\n",
      "|0.17004|12.5| 7.87| 0.0|0.524|6.004| 85.9|6.5921|5.0|311.0|   15.2|386.71| 17.1| 18.9|[0.17004,12.5,7.8...|\n",
      "|0.22489|12.5| 7.87| 0.0|0.524|6.377| 94.3|6.3467|5.0|311.0|   15.2|392.52|20.45| 15.0|[0.22489,12.5,7.8...|\n",
      "|0.11747|12.5| 7.87| 0.0|0.524|6.009| 82.9|6.2267|5.0|311.0|   15.2| 396.9|13.27| 18.9|[0.11747,12.5,7.8...|\n",
      "|0.09378|12.5| 7.87| 0.0|0.524|5.889| 39.0|5.4509|5.0|311.0|   15.2| 390.5|15.71| 21.7|[0.09378,12.5,7.8...|\n",
      "|0.62976| 0.0| 8.14| 0.0|0.538|5.949| 61.8|4.7075|4.0|307.0|   21.0| 396.9| 8.26| 20.4|[0.62976,0.0,8.14...|\n",
      "|0.63796| 0.0| 8.14| 0.0|0.538|6.096| 84.5|4.4619|4.0|307.0|   21.0|380.02|10.26| 18.2|[0.63796,0.0,8.14...|\n",
      "|0.62739| 0.0| 8.14| 0.0|0.538|5.834| 56.5|4.4986|4.0|307.0|   21.0|395.62| 8.47| 19.9|[0.62739,0.0,8.14...|\n",
      "|1.05393| 0.0| 8.14| 0.0|0.538|5.935| 29.3|4.4986|4.0|307.0|   21.0|386.85| 6.58| 23.1|[1.05393,0.0,8.14...|\n",
      "| 0.7842| 0.0| 8.14| 0.0|0.538| 5.99| 81.7|4.2579|4.0|307.0|   21.0|386.75|14.67| 17.5|[0.7842,0.0,8.14,...|\n",
      "|0.80271| 0.0| 8.14| 0.0|0.538|5.456| 36.6|3.7965|4.0|307.0|   21.0|288.99|11.69| 20.2|[0.80271,0.0,8.14...|\n",
      "| 0.7258| 0.0| 8.14| 0.0|0.538|5.727| 69.5|3.7965|4.0|307.0|   21.0|390.95|11.28| 18.2|[0.7258,0.0,8.14,...|\n",
      "+-------+----+-----+----+-----+-----+-----+------+---+-----+-------+------+-----+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3472566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"price\")\n",
    "model = lr.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28d03c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7406426641094093\n"
     ]
    }
   ],
   "source": [
    "summary = model.evaluate(dataset)\n",
    "print(summary.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea52f359",
   "metadata": {},
   "source": [
    "`Note:` One thing we need to note here is that different algorithms may have different results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56019482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        prediction|\n",
      "+------------------+\n",
      "|30.003843377018672|\n",
      "|25.025562379052605|\n",
      "|30.567596718599706|\n",
      "| 28.60703648872773|\n",
      "|27.943524232871702|\n",
      "| 25.25628446154206|\n",
      "|23.001808268484787|\n",
      "|19.535988428753562|\n",
      "|11.523636853127133|\n",
      "|  18.9202621070742|\n",
      "| 18.99949651112896|\n",
      "|21.586795681398485|\n",
      "| 20.90652152783407|\n",
      "| 19.55290281058366|\n",
      "|19.283482050092314|\n",
      "|19.297483208230954|\n",
      "| 20.52750979116518|\n",
      "|16.911401346799252|\n",
      "|16.178011056575237|\n",
      "|18.406136033335542|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = model.transform(dataset)\n",
    "output.select(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab964c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|price|\n",
      "+-----+\n",
      "| 24.0|\n",
      "| 21.6|\n",
      "| 34.7|\n",
      "| 33.4|\n",
      "| 36.2|\n",
      "| 28.7|\n",
      "| 22.9|\n",
      "| 27.1|\n",
      "| 16.5|\n",
      "| 18.9|\n",
      "| 15.0|\n",
      "| 18.9|\n",
      "| 21.7|\n",
      "| 20.4|\n",
      "| 18.2|\n",
      "| 19.9|\n",
      "| 23.1|\n",
      "| 17.5|\n",
      "| 20.2|\n",
      "| 18.2|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select(\"price\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e71188e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406426641094093"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating in PySpark Regression evaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "evaluator.evaluate(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5966469a",
   "metadata": {},
   "source": [
    "`Oops`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53189847",
   "metadata": {},
   "source": [
    "### Classification with MLLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1742a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eba019c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(r\"D:\\Data Science\\IIITB\\Data Engineering - II\\Module - 6 (Analytics Using PySpark)\\2. Linear Regression Using PySpark\\iris+(1).csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "929fa618",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[x for x in df.columns if x != \"species\"],\n",
    "                           outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39c63713",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562482ea",
   "metadata": {},
   "source": [
    "`Note`: Similar to Regression problem, we cannot apply simple Classification fit directly."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad704558",
   "metadata": {},
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"price\")\n",
    "model = lr.fit(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3683e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-------------+---------------+------------+\n",
      "|sepal_length|sepal_width|petal_length|petal_widthCm|        species|speciesIndex|\n",
      "+------------+-----------+------------+-------------+---------------+------------+\n",
      "|         5.2|        3.5|         1.5|          0.2|    Iris-setosa|         0.0|\n",
      "|         4.8|        3.1|         1.6|          0.2|    Iris-setosa|         0.0|\n",
      "|         4.4|        3.0|         1.3|          0.2|    Iris-setosa|         0.0|\n",
      "|         4.4|        3.2|         1.3|          0.2|    Iris-setosa|         0.0|\n",
      "|         5.0|        3.5|         1.6|          0.6|    Iris-setosa|         0.0|\n",
      "|         5.1|        3.8|         1.9|          0.4|    Iris-setosa|         0.0|\n",
      "|         4.8|        3.0|         1.4|          0.3|    Iris-setosa|         0.0|\n",
      "|         6.9|        3.1|         4.9|          1.5|Iris-versicolor|         1.0|\n",
      "|         4.9|        2.4|         3.3|          1.0|Iris-versicolor|         1.0|\n",
      "|         6.6|        2.9|         4.6|          1.3|Iris-versicolor|         1.0|\n",
      "|         6.4|        2.9|         4.3|          1.3|Iris-versicolor|         1.0|\n",
      "|         5.5|        2.4|         3.8|          1.1|Iris-versicolor|         1.0|\n",
      "|         6.0|        2.7|         5.1|          1.6|Iris-versicolor|         1.0|\n",
      "|         6.3|        2.3|         4.4|          1.3|Iris-versicolor|         1.0|\n",
      "|         5.0|        2.3|         3.3|          1.0|Iris-versicolor|         1.0|\n",
      "|         5.7|        2.8|         4.1|          1.3|Iris-versicolor|         1.0|\n",
      "|         4.9|        2.5|         4.5|          1.7| Iris-virginica|         2.0|\n",
      "|         6.4|        2.7|         5.3|          1.9| Iris-virginica|         2.0|\n",
      "|         5.7|        2.5|         5.0|          2.0| Iris-virginica|         2.0|\n",
      "|         5.8|        2.7|         5.1|          1.9| Iris-virginica|         2.0|\n",
      "+------------+-----------+------------+-------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"species\", outputCol=\"speciesIndex\")\n",
    "\n",
    "iris = indexer.fit(df).transform(df)\n",
    "\n",
    "iris.sample(fraction = 0.1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c26224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[col for col in df.columns if not col.startswith(\"species\")],\n",
    "                           outputCol=\"features\")\n",
    "dataset = assembler.transform(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7033311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_widthCm: double (nullable = true)\n",
      " |-- species: string (nullable = true)\n",
      " |-- speciesIndex: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab9d9c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"speciesIndex\")\n",
    "model = lr.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10ce86e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = model.evaluate(dataset)\n",
    "summary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cc34ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will split datset in train-test set to evaluate because this is too convenient\n",
    "trainData, testData = dataset.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "723fec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(trainData)\n",
    "summary = model.evaluate(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9fd335a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9512195121951219"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5296375c",
   "metadata": {},
   "source": [
    "### Using Naive Bayes with MLLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07df88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bb26410",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, testData = dataset.randomSplit([0.6, 0.4])\n",
    "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"speciesIndex\")\n",
    "model = nb.fit(trainData)\n",
    "output = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e23c25b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44745395449620795"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"speciesIndex\")\n",
    "evaluator.evaluate(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
