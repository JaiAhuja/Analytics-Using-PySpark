{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark\n!pip install findspark","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:06:35.330287Z","iopub.execute_input":"2022-01-08T17:06:35.330871Z","iopub.status.idle":"2022-01-08T17:07:36.197654Z","shell.execute_reply.started":"2022-01-08T17:06:35.330731Z","shell.execute_reply":"2022-01-08T17:07:36.1967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import findspark\nimport pyspark\n\nimport os\nimport functools as reduce\nfrom pyspark.context import SparkContext\nfrom pyspark.sql import DataFrame, SQLContext, SparkSession, Window\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\n\n# Importing other MLlib Libraries\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nconf = pyspark.SparkConf().setAppName('Credit Card Fraud Detection').setMaster('Kaggle')\nsc = pyspark.SparkContext(conf = conf)\nspark = SparkSession(sc)\nsqlContext = SQLContext(sc)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:15:01.288468Z","iopub.execute_input":"2022-01-08T17:15:01.288837Z","iopub.status.idle":"2022-01-08T17:15:03.374729Z","shell.execute_reply.started":"2022-01-08T17:15:01.288802Z","shell.execute_reply":"2022-01-08T17:15:03.373115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing other relevant libraries\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:07:38.943879Z","iopub.status.idle":"2022-01-08T17:07:38.945163Z","shell.execute_reply.started":"2022-01-08T17:07:38.944809Z","shell.execute_reply":"2022-01-08T17:07:38.944846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spark","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:07:38.94674Z","iopub.status.idle":"2022-01-08T17:07:38.947247Z","shell.execute_reply.started":"2022-01-08T17:07:38.946967Z","shell.execute_reply":"2022-01-08T17:07:38.946993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset Link: spark-practice-de.s3.amazonaws.com/creditcard_fraud.rar","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:07:38.948904Z","iopub.status.idle":"2022-01-08T17:07:38.949723Z","shell.execute_reply.started":"2022-01-08T17:07:38.949439Z","shell.execute_reply":"2022-01-08T17:07:38.949466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading the dataset\ndf = spark.read.csv(\"../input/creditcardfraud/creditcard.csv\", header=True, inferSchema=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:07:38.950752Z","iopub.status.idle":"2022-01-08T17:07:38.951096Z","shell.execute_reply.started":"2022-01-08T17:07:38.950899Z","shell.execute_reply":"2022-01-08T17:07:38.950916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:07:38.952534Z","iopub.status.idle":"2022-01-08T17:07:38.953304Z","shell.execute_reply.started":"2022-01-08T17:07:38.953086Z","shell.execute_reply":"2022-01-08T17:07:38.953114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count of Fraudulent and Non-Fraudulent Transactions\ndf.groupby(\"Class\").count().show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:07:38.954366Z","iopub.status.idle":"2022-01-08T17:07:38.95513Z","shell.execute_reply.started":"2022-01-08T17:07:38.954889Z","shell.execute_reply":"2022-01-08T17:07:38.954917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:07:38.956241Z","iopub.status.idle":"2022-01-08T17:07:38.957Z","shell.execute_reply.started":"2022-01-08T17:07:38.95676Z","shell.execute_reply":"2022-01-08T17:07:38.956793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting distinct counts of the columns in the dataset\ndf.agg(*(countDistinct(col(c)).alias(c) for c in df.columns)).show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:07:38.958065Z","iopub.status.idle":"2022-01-08T17:07:38.958774Z","shell.execute_reply.started":"2022-01-08T17:07:38.95856Z","shell.execute_reply":"2022-01-08T17:07:38.958588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assembler = VectorAssembler(inputCols=[col for col in df.columns if col != \"Class\"],\n                           outputCol=\"features\")","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:07:38.959959Z","iopub.status.idle":"2022-01-08T17:07:38.960317Z","shell.execute_reply.started":"2022-01-08T17:07:38.96014Z","shell.execute_reply":"2022-01-08T17:07:38.960162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = assembler.transform(df)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:07:38.961592Z","iopub.status.idle":"2022-01-08T17:07:38.961964Z","shell.execute_reply.started":"2022-01-08T17:07:38.961753Z","shell.execute_reply":"2022-01-08T17:07:38.961774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.show(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:07:38.963901Z","iopub.status.idle":"2022-01-08T17:07:38.964481Z","shell.execute_reply.started":"2022-01-08T17:07:38.964205Z","shell.execute_reply":"2022-01-08T17:07:38.964235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Since, we only need label and features column for model building. Hence, selecting only relevant columns\nmodel_data = dataset.select([\"features\", \"Class\"])\nmodel_data = model_data.withColumnRenamed(\"Class\", \"label\")\nmodel_data.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:07:38.966176Z","iopub.status.idle":"2022-01-08T17:07:38.96698Z","shell.execute_reply.started":"2022-01-08T17:07:38.966686Z","shell.execute_reply":"2022-01-08T17:07:38.966718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Building\np_train = [0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95]\ntrain_ROC = []\ntest_ROC = []\n\nfor p in p_train:\n    \n    print(\"Training Split at\", str(p),\"%\")\n    # Splitting the dataset in train and test\n    train, test = model_data.randomSplit([p, 1-p])\n    lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n    model = lr.fit(train)\n\n    # Plot on Train dataset\n    trainingSummary = model.summary\n    roc = trainingSummary.roc.toPandas()\n    plt.plot(roc[\"FPR\"], roc[\"TPR\"])\n    plt.ylabel(\"False Positive Rate\")\n    plt.xlabel(\"True Positive Rate\")\n    plt.title(\"ROC Curve\")\n    plt.show()\n\n    print(\"Training set areaUnderCurve: \" + str(trainingSummary.areaUnderROC))\n    train_ROC.append(trainingSummary.areaUnderROC)\n    \n    # Precision Recall Curve\n    pr = trainingSummary.pr.toPandas()\n    plt.plot(pr[\"recall\"], pr[\"precision\"])\n    plt.ylabel(\"Precision\")\n    plt.xlabel(\"Recall\")\n    plt.show()\n\n    # Evaluating on test dataset\n    summary = model.evaluate(test)\n    summary.accuracy\n\n    output = model.transform(test)\n\n    evaluator = BinaryClassificationEvaluator()\n    print(\"Test Area under ROC\", evaluator.evaluate(output))\n    \n    test_ROC.append(evaluator.evaluate(output))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-08T17:07:38.968672Z","iopub.status.idle":"2022-01-08T17:07:38.968998Z","shell.execute_reply.started":"2022-01-08T17:07:38.968837Z","shell.execute_reply":"2022-01-08T17:07:38.968854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting\nplt.plot(p_train, train_ROC, \"ro-\", label = \"Train\")\nplt.plot(p_train, test_ROC, \"g\", label = \"Test\")\nplt.xlabel(\"Training Size\")\nplt.ylabel(\"Area under ROC Curve\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:07:38.969934Z","iopub.status.idle":"2022-01-08T17:07:38.970283Z","shell.execute_reply.started":"2022-01-08T17:07:38.970105Z","shell.execute_reply":"2022-01-08T17:07:38.970128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"print(\"The best Accuracy is received: \"+str(sorted(test_ROC)[-1]))","metadata":{}}]}